{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-03-11T16:35:07.796596Z",
     "start_time": "2025-03-11T16:35:07.772139Z"
    }
   },
   "source": [
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "rs = 132\n",
    "dataset = pd.read_csv('./data/dataset.csv', dtype={\"股票代码\": \"object\"})\n",
    "dataset.set_index('股票简称', inplace=True)\n",
    "\n",
    "features = ['净资产收益率(%)', '资产报酬率(%)', '营业收入增长率(%)', '成本费用利润率(%)', '总资产周转率(%)', '应收账款周转率(%)', '存货周转率(%)', '营业周期', '技术人员占比(%)', '研发营收比(%)', '发明专利申请数', '数字化软硬件投入比(%)', '数字化战略导向前瞻性', '数字化战略导向持续性', '数字化战略导向广度', '数字化战略导向强度', '数字发明专利', '数字国家级奖项', '数字创新论文', '数字创新标准', '数字创新资质', '管理层数字职务设立', '两权分离率(%)', '数字人力计划投入', '科技创新基地建设', '员工人均营收比(%)', '提供岗位增长率(%)', '员工收入增长率(%)', '社会责任报告质量', '供应链合作伙伴', '数字化供应链覆盖度', '客户集中度(%)', '供应商集中度(%)']\n",
    "label_name = 'score'\n",
    "unit_map = dataset[['股票代码', '行业代码', '所属省份']].to_dict()\n",
    "# 获取数据集和标签值\n",
    "y : pd.Series = dataset[label_name]\n",
    "X : pd.DataFrame = dataset[features].copy(deep=True).astype(\"float\")\n",
    "# 数据预处理：1.极差标准化；2.数据集划分。\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=rs)\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train_s = scaler.transform(X_train)\n",
    "X_test_s = scaler.transform(X_test)"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-11T16:35:14.651826Z",
     "start_time": "2025-03-11T16:35:14.627151Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.model_selection import KFold, GridSearchCV, cross_val_score\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "# 一般机器学习模型的训练与优化\n",
    "\n",
    "# 1.最小二乘线性回归\n",
    "model = LinearRegression(n_jobs=-1)\n",
    "model.fit(X_train_s, y_train)\n",
    "y_pred = model.predict(X_test_s)\n",
    "print(f\"OLS Regression | r2:{r2_score(y_test, y_pred)} | mean_squared_error:{mean_squared_error(y_test, y_pred):.2} | mean_absolute_error:{mean_absolute_error(y_test, y_pred):.2}。\\n 因子分析的结果实际是对原结果进行线性转化的过程，因此最小二乘法能够较为精确的计算出实际权重。\")"
   ],
   "id": "131fc53b9ebe80e3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OLS Regression | r2:1.0 | mean_squared_error:3.9e-33 | mean_absolute_error:4.8e-17。\n",
      " 因子分析的结果实际是对原结果进行线性转化的过程，因此最小二乘法能够较为精确的计算出实际权重。\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import numpy as np\n",
    "\n",
    "\n"
   ],
   "id": "6591e3691387c6e2"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "end_time": "2025-03-11T16:37:13.381610Z",
     "start_time": "2025-03-11T16:35:19.006869Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# 基于树模型的参数优化基本流程为：首先计算单个参数的大致范围，随后进行网格搜索。\n",
    "# 决策树算法优化思路:\n",
    "\n",
    "# 1.优化ccp_alpha(网格搜索)；\n",
    "\n",
    "# model = DecisionTreeRegressor(random_state=rs)\n",
    "# path = model.cost_complexity_pruning_path(X_train_s, y_train)\n",
    "# param_grid = {'ccp_alpha': path.ccp_alphas}\n",
    "# kfold = KFold(n_splits=10, shuffle=True, random_state=1)\n",
    "# model = GridSearchCV(DecisionTreeRegressor(random_state=rs), param_grid, cv=kfold)\n",
    "# model.fit(X_train_s, y_train)\n",
    "# print(model.best_params_)\n",
    "\n",
    "# 2.单参数优化；\n",
    "model = DecisionTreeRegressor(max_features=\"sqrt\", random_state=1)\n",
    "path = model.cost_complexity_pruning_path(X_train_s, y_train)\n",
    "param_grid = {\n",
    "    'ccp_alpha': path.ccp_alphas,  # 剪枝参数\n",
    "    'max_depth': np.arange(5, 15, 1),  # 决策树最大深度，用来防止过拟合; \n",
    "    'min_samples_split': np.arange(1, 3, 1),  # 分裂节点所需的最小样本数，也就是如果样本数小于这个值就不划分了。\n",
    "    'min_samples_leaf': np.arange(1, 4, 1)  # 叶节点所需的最小样本数，如果样本数小于这个，就不划分了。用来防止过拟合\n",
    "}\n",
    "# 2.网格法参数微调\n",
    "kfold = KFold(n_splits=10, shuffle=True, random_state=rs)\n",
    "model = GridSearchCV(DecisionTreeRegressor(max_features=\"sqrt\", random_state=rs), param_grid, cv=kfold, n_jobs=-1)\n",
    "model.fit(X_train_s, y_train)\n",
    "\n",
    "# 决策树最优超参数：{'ccp_alpha': 0.7814179316082759, 'max_depth': 11, 'min_samples_leaf': 1, 'min_samples_split': 2} ；综合得分0.7849455038096266\n",
    "print(f\"决策树最优超参数：{model.best_params_}\\n 综合得分{model.best_estimator_.score(X_test_s, y_test)}\")"
   ],
   "id": "5ee823de33dbfc86",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-03-09T22:59:58.027379Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "# 随机森林参数优化：https://www.jianshu.com/p/f5b45a60289f\n",
    "param_grid = {\n",
    "    'max_depth': np.arange(2, 30, 1),  # 树的最大深度\n",
    "    'n_estimators': np.arange(2, 30, 1),  # 森林中树的数量\n",
    "    'min_samples_split': [2, 3, 4, 5],  # 分裂节点所需的最小样本数\n",
    "    'min_samples_leaf': [1, 2, 3],  # 叶节点所需的最小样本数\n",
    "    'max_features': np.arange(2, 30, 1)  # 每次分裂时考虑的特征数量\n",
    "}\n",
    "\n",
    "model = RandomForestRegressor(verbose=0, random_state=rs, min_samples_split=2, min_samples_leaf=2)\n",
    "kfold = KFold(n_splits=10, shuffle=True, random_state=rs)\n",
    "model = GridSearchCV(model, param_grid, cv=kfold, scoring='r2', verbose=0, n_jobs=-1)\n",
    "model.fit(X_train_s, y_train)\n",
    "# RandomForest 最优超参数：{'max_depth': 13, 'max_features': 11, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 7}\n",
    " # 综合得分0.8483375813154402\n",
    "\n",
    "print(f\"RandomForest 最优超参数：{model.best_params_}\\n 综合得分{model.best_estimator_.score(X_test_s, y_test)}\")"
   ],
   "id": "d27429b14924eb44",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method IPythonKernel._clean_thread_parent_frames of <ipykernel.ipkernel.IPythonKernel object at 0x106dc1910>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/xieheng/projects/envs/digital/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 775, in _clean_thread_parent_frames\n",
      "    def _clean_thread_parent_frames(\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[6], line 14\u001B[0m\n\u001B[1;32m     12\u001B[0m kfold \u001B[38;5;241m=\u001B[39m KFold(n_splits\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m10\u001B[39m, shuffle\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, random_state\u001B[38;5;241m=\u001B[39mrs)\n\u001B[1;32m     13\u001B[0m model \u001B[38;5;241m=\u001B[39m GridSearchCV(model, param_grid, cv\u001B[38;5;241m=\u001B[39mkfold, scoring\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mr2\u001B[39m\u001B[38;5;124m'\u001B[39m, verbose\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m, n_jobs\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m---> 14\u001B[0m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_train_s\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     15\u001B[0m \u001B[38;5;66;03m# RandomForest 最优超参数：{'max_depth': 13, 'max_features': 11, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 7}\u001B[39;00m\n\u001B[1;32m     16\u001B[0m  \u001B[38;5;66;03m# 综合得分0.8483375813154402\u001B[39;00m\n\u001B[1;32m     18\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mRandomForest 最优超参数：\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mmodel\u001B[38;5;241m.\u001B[39mbest_params_\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m 综合得分\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mmodel\u001B[38;5;241m.\u001B[39mbest_estimator_\u001B[38;5;241m.\u001B[39mscore(X_test_s,\u001B[38;5;250m \u001B[39my_test)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/projects/envs/digital/lib/python3.9/site-packages/sklearn/base.py:1389\u001B[0m, in \u001B[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001B[0;34m(estimator, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1382\u001B[0m     estimator\u001B[38;5;241m.\u001B[39m_validate_params()\n\u001B[1;32m   1384\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[1;32m   1385\u001B[0m     skip_parameter_validation\u001B[38;5;241m=\u001B[39m(\n\u001B[1;32m   1386\u001B[0m         prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[1;32m   1387\u001B[0m     )\n\u001B[1;32m   1388\u001B[0m ):\n\u001B[0;32m-> 1389\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfit_method\u001B[49m\u001B[43m(\u001B[49m\u001B[43mestimator\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/projects/envs/digital/lib/python3.9/site-packages/sklearn/model_selection/_search.py:1024\u001B[0m, in \u001B[0;36mBaseSearchCV.fit\u001B[0;34m(self, X, y, **params)\u001B[0m\n\u001B[1;32m   1018\u001B[0m     results \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_format_results(\n\u001B[1;32m   1019\u001B[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001B[1;32m   1020\u001B[0m     )\n\u001B[1;32m   1022\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m results\n\u001B[0;32m-> 1024\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_run_search\u001B[49m\u001B[43m(\u001B[49m\u001B[43mevaluate_candidates\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1026\u001B[0m \u001B[38;5;66;03m# multimetric is determined here because in the case of a callable\u001B[39;00m\n\u001B[1;32m   1027\u001B[0m \u001B[38;5;66;03m# self.scoring the return type is only known after calling\u001B[39;00m\n\u001B[1;32m   1028\u001B[0m first_test_score \u001B[38;5;241m=\u001B[39m all_out[\u001B[38;5;241m0\u001B[39m][\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtest_scores\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n",
      "File \u001B[0;32m~/projects/envs/digital/lib/python3.9/site-packages/sklearn/model_selection/_search.py:1571\u001B[0m, in \u001B[0;36mGridSearchCV._run_search\u001B[0;34m(self, evaluate_candidates)\u001B[0m\n\u001B[1;32m   1569\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21m_run_search\u001B[39m(\u001B[38;5;28mself\u001B[39m, evaluate_candidates):\n\u001B[1;32m   1570\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001B[39;00m\n\u001B[0;32m-> 1571\u001B[0m     \u001B[43mevaluate_candidates\u001B[49m\u001B[43m(\u001B[49m\u001B[43mParameterGrid\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mparam_grid\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/projects/envs/digital/lib/python3.9/site-packages/sklearn/model_selection/_search.py:970\u001B[0m, in \u001B[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001B[0;34m(candidate_params, cv, more_results)\u001B[0m\n\u001B[1;32m    962\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mverbose \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m    963\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\n\u001B[1;32m    964\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFitting \u001B[39m\u001B[38;5;132;01m{0}\u001B[39;00m\u001B[38;5;124m folds for each of \u001B[39m\u001B[38;5;132;01m{1}\u001B[39;00m\u001B[38;5;124m candidates,\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    965\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m totalling \u001B[39m\u001B[38;5;132;01m{2}\u001B[39;00m\u001B[38;5;124m fits\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(\n\u001B[1;32m    966\u001B[0m             n_splits, n_candidates, n_candidates \u001B[38;5;241m*\u001B[39m n_splits\n\u001B[1;32m    967\u001B[0m         )\n\u001B[1;32m    968\u001B[0m     )\n\u001B[0;32m--> 970\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[43mparallel\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    971\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdelayed\u001B[49m\u001B[43m(\u001B[49m\u001B[43m_fit_and_score\u001B[49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    972\u001B[0m \u001B[43m        \u001B[49m\u001B[43mclone\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbase_estimator\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    973\u001B[0m \u001B[43m        \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    974\u001B[0m \u001B[43m        \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    975\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtrain\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    976\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtest\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtest\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    977\u001B[0m \u001B[43m        \u001B[49m\u001B[43mparameters\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mparameters\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    978\u001B[0m \u001B[43m        \u001B[49m\u001B[43msplit_progress\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43msplit_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_splits\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    979\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcandidate_progress\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcand_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_candidates\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    980\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mfit_and_score_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    981\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    982\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43mcand_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mparameters\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43msplit_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtest\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mproduct\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    983\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43menumerate\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcandidate_params\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    984\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43menumerate\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcv\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msplit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mrouted_params\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msplitter\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msplit\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    985\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    986\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    988\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(out) \u001B[38;5;241m<\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m    989\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    990\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNo fits were performed. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    991\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mWas the CV iterator empty? \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    992\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mWere there no candidates?\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    993\u001B[0m     )\n",
      "File \u001B[0;32m~/projects/envs/digital/lib/python3.9/site-packages/sklearn/utils/parallel.py:77\u001B[0m, in \u001B[0;36mParallel.__call__\u001B[0;34m(self, iterable)\u001B[0m\n\u001B[1;32m     72\u001B[0m config \u001B[38;5;241m=\u001B[39m get_config()\n\u001B[1;32m     73\u001B[0m iterable_with_config \u001B[38;5;241m=\u001B[39m (\n\u001B[1;32m     74\u001B[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001B[1;32m     75\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m delayed_func, args, kwargs \u001B[38;5;129;01min\u001B[39;00m iterable\n\u001B[1;32m     76\u001B[0m )\n\u001B[0;32m---> 77\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__call__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43miterable_with_config\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/projects/envs/digital/lib/python3.9/site-packages/joblib/parallel.py:2007\u001B[0m, in \u001B[0;36mParallel.__call__\u001B[0;34m(self, iterable)\u001B[0m\n\u001B[1;32m   2001\u001B[0m \u001B[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001B[39;00m\n\u001B[1;32m   2002\u001B[0m \u001B[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001B[39;00m\n\u001B[1;32m   2003\u001B[0m \u001B[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001B[39;00m\n\u001B[1;32m   2004\u001B[0m \u001B[38;5;66;03m# dispatch of the tasks to the workers.\u001B[39;00m\n\u001B[1;32m   2005\u001B[0m \u001B[38;5;28mnext\u001B[39m(output)\n\u001B[0;32m-> 2007\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m output \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mreturn_generator \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;43mlist\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43moutput\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/projects/envs/digital/lib/python3.9/site-packages/joblib/parallel.py:1650\u001B[0m, in \u001B[0;36mParallel._get_outputs\u001B[0;34m(self, iterator, pre_dispatch)\u001B[0m\n\u001B[1;32m   1647\u001B[0m     \u001B[38;5;28;01myield\u001B[39;00m\n\u001B[1;32m   1649\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backend\u001B[38;5;241m.\u001B[39mretrieval_context():\n\u001B[0;32m-> 1650\u001B[0m         \u001B[38;5;28;01myield from\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_retrieve()\n\u001B[1;32m   1652\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mGeneratorExit\u001B[39;00m:\n\u001B[1;32m   1653\u001B[0m     \u001B[38;5;66;03m# The generator has been garbage collected before being fully\u001B[39;00m\n\u001B[1;32m   1654\u001B[0m     \u001B[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001B[39;00m\n\u001B[1;32m   1655\u001B[0m     \u001B[38;5;66;03m# the user if necessary.\u001B[39;00m\n\u001B[1;32m   1656\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_exception \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "File \u001B[0;32m~/projects/envs/digital/lib/python3.9/site-packages/joblib/parallel.py:1762\u001B[0m, in \u001B[0;36mParallel._retrieve\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1757\u001B[0m \u001B[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001B[39;00m\n\u001B[1;32m   1758\u001B[0m \u001B[38;5;66;03m# async callbacks to progress.\u001B[39;00m\n\u001B[1;32m   1759\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m ((\u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jobs) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m) \u001B[38;5;129;01mor\u001B[39;00m\n\u001B[1;32m   1760\u001B[0m     (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jobs[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39mget_status(\n\u001B[1;32m   1761\u001B[0m         timeout\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtimeout) \u001B[38;5;241m==\u001B[39m TASK_PENDING)):\n\u001B[0;32m-> 1762\u001B[0m     \u001B[43mtime\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msleep\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m0.01\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1763\u001B[0m     \u001B[38;5;28;01mcontinue\u001B[39;00m\n\u001B[1;32m   1765\u001B[0m \u001B[38;5;66;03m# We need to be careful: the job list can be filling up as\u001B[39;00m\n\u001B[1;32m   1766\u001B[0m \u001B[38;5;66;03m# we empty it and Python list are not thread-safe by\u001B[39;00m\n\u001B[1;32m   1767\u001B[0m \u001B[38;5;66;03m# default hence the use of the lock\u001B[39;00m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from xgboost import XGBRegressor\n",
    "\n",
    "# 3.xgboost参数优化：https://www.cnblogs.com/showmeai/p/16037327.html；\n",
    "params = {\n",
    "   \"objective\": 'reg:squarederror',\n",
    "   \"n_estimators\": 10,\n",
    "   \"max_depth\": 9,\n",
    "   \"learning_rate\": 0.24,\n",
    "   \"subsample\": 0.2,\n",
    "   \"min_child_weight\": 1,\n",
    "   \"gamma\": 0.1,\n",
    "   \"colsample_bytree\": 0.8,\n",
    "   \"reg_alpha\": 0,\n",
    "   \"reg_lambda\": 0,\n",
    "   # \"scale_pos_weight\": 1,\n",
    "}\n",
    "param_grid = {\n",
    "    'n_estimators': np.arange(18, 24, 1),\n",
    "    'max_depth': np.arange(8, 12, 1),\n",
    "    'learning_rate': np.arange(0.15, 0.25, 0.01), # [0.05, 0.1, 0.2]\n",
    "    \"min_child_weight\": [4, 5, 6, 7],\n",
    "    # \"gamma\": [0, 0.1],\n",
    "    'subsample': np.arange(0.4, 0.7, 0.1),\n",
    "    'colsample_bytree': np.arange(0.95, 1.2, 0.01),\n",
    "}\n",
    "\n",
    "model = XGBRegressor(random_state=rs)\n",
    "kfold = KFold(n_splits=10, shuffle=True, random_state=rs)\n",
    "model = GridSearchCV(model, param_grid, cv=kfold, scoring='r2', verbose=0, n_jobs=-1)\n",
    "model.fit(X_train_s, y_train)  \n",
    "print(f\"XGBRegressor 最优超参数：{model.best_params_}\\n 综合得分{model.best_estimator_.score(X_test_s, y_test)}\")\n",
    "\n",
    "# XGBRegressor 最优超参数：{'colsample_bytree': 0.9800000000000001, 'gamma': 0.1, 'learning_rate': 0.2, 'max_depth': 11, 'min_child_weight': 5, 'n_estimators': 23, 'subsample': 0.5}   综合得分0.8801265955806522"
   ],
   "id": "5f9d54a550d7bc21",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from catboost import CatBoostRegressor\n",
    "\n",
    "# 4.catboost参数优化\n",
    "param_grid = {\n",
    "    # 'iterations': np.arange(100, 401, 50),\n",
    "    'depth': [2, 3, 4, 5], \n",
    "    'learning_rate': np.arange(0.14, 0.38, 0.01),\n",
    "    'l2_leaf_reg': np.arange(0.2, 1.6, 0.1),\n",
    "    # 'bagging_temperature': [0.1, 0.3],\n",
    "    # 'border_count': np.arange(35, 190, 1)\n",
    "}\n",
    "# 分布计算\n",
    "model = CatBoostRegressor(random_state=rs, verbose=0, train_dir=None, allow_writing_files=False, iterations=400, bagging_temperature=0.1, border_count=182)\n",
    "kfold = KFold(n_splits=10, shuffle=True, random_state=rs)\n",
    "model = GridSearchCV(model, param_grid, cv=kfold, scoring='r2', verbose=0, n_jobs=-1)\n",
    "model.fit(X_train_s, y_train) \n",
    "print(f\"CatBoost 最优超参数：{model.best_params_}\\n 综合得分{model.best_estimator_.score(X_test_s, y_test)}\")\n",
    "\n",
    "# CatBoost 最优超参数：{'depth': 2, 'l2_leaf_reg': 0.6000000000000001, 'learning_rate': 0.15000000000000002} 综合得分0.9445921278676876"
   ],
   "id": "6cb6ff27c8f16f51",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "params = {\n",
    "    \"objective\": 'mse',\n",
    "    'max_depth': 3,\n",
    "    \"n_estimators\": 200,\n",
    "    \"learning_rate\": 0.1,\n",
    "    'min_child_samples': 7,\n",
    "    'reg_alpha': 0,\n",
    "    'reg_lambda': 0,\n",
    "    \"force_col_wise\": True,\n",
    "    \"subsample\": 0.8,\n",
    "    'colsample_bytree': 0.26,\n",
    "    \"num_leaves\": 7  # 一般设置为(0, 2^max_depth - 1]的一个数值。是一个需要重点调节的参数，对模型性能影响很大。\n",
    "}\n",
    "param_grid = {\n",
    "    'max_depth': [2, 3, 4, 5],\n",
    "    'learning_rate': [0.06, 0.1, 0.12, 0.17, 0.23, 0.24, 0.25, 0.27],\n",
    "    # \"n_estimators\": 100,\n",
    "    'min_child_samples': [5, 6, 7, 8], # 6附近\n",
    "    'colsample_bytree': np.arange(0.25, 0.45, 0.01),  # 0.25和0.45附近\n",
    "    \"num_leaves\": np.arange(3, 8, 1)\n",
    "}\n",
    "model = LGBMRegressor(n_jobs=-1, random_state=rs, verbosity=-1, **params)\n",
    "kfold = KFold(n_splits=10, shuffle=True, random_state=rs)\n",
    "model = GridSearchCV(model, param_grid, cv=kfold, scoring='r2', verbose=0, n_jobs=-1)\n",
    "model.fit(X_train_s, y_train) \n",
    "print(f\"LGBMBoost 最优超参数：{model.best_params_}\\n 综合得分{model.best_estimator_.score(X_test_s, y_test)}\")"
   ],
   "id": "7fb2d0875d95af1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from lightgbm import LGBMRegressor\n",
    "params = {\n",
    "    \"objective\": 'mse',\n",
    "    'max_depth': 3,\n",
    "    \"n_estimators\": 200,\n",
    "    'learning_rate': 0.15,\n",
    "    'min_child_samples': 7, \n",
    "    'reg_alpha': 0,\n",
    "    'reg_lambda': 0,\n",
    "    \"force_col_wise\": True,\n",
    "    \"subsample\": 0.8,\n",
    "    'colsample_bytree': 0.32,\n",
    "    \"num_leaves\": 6\n",
    "}\n",
    "model = LGBMRegressor(n_jobs=-1, random_state=rs, verbosity=-1, **params)\n",
    "model.fit(X_train_s, y_train)\n",
    "print(model.score(X_test_s, y_test))"
   ],
   "id": "671edd0789e1e7d1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from tensorflow import keras\n",
    "from utils.methods import r2\n",
    "\n",
    "# Sequential 模型适用于普通层堆栈 其中，每层只有一个 input Tensor 和一个 Output Tensor。\n",
    "model = keras.models.Sequential()\n",
    "# model.add(keras.Input(shape=(X_train_s.shape[1], )))\n",
    "model.add(keras.layers.Dense(units=30, activation='relu', name=\"layer1\", input_shape=(X_train_s.shape[1], ),\n",
    "                               kernel_regularizer=keras.regularizers.l2(0.02)))\n",
    "model.add(keras.layers.Dropout(0.01))\n",
    "\n",
    "# 增加输出层\n",
    "model.add(keras.layers.Dense(units=1, name=\"output\"))\n",
    "optimizer = keras.optimizers.Adam(learning_rate=0.02)\n",
    "model.compile(optimizer=optimizer, loss='mse', metrics=['mse', r2, 'mae'])\n",
    "# 查看模型结构\n",
    "# utils.plot_model(model, \"./assert/feature_importance/bp_model_structure.png\", show_shapes=True)\n",
    "# model.summary()\n",
    "early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)\n",
    "hist = model.fit(X_train_s, y_train, validation_split=0.2, epochs=300, batch_size=30, shuffle=False, verbose=0,\n",
    "                         callbacks=[early_stopping])\n",
    "# validation_split是训练集验证集拆分，epochs代表训练300轮，batch_size代表在批量梯度下降时每次选择16个样本，shuffle代表在训练过程中不会将数据反复打乱\n",
    "# verbose：日志显示，0为不在标准输出流输出日志信息，1为输出进度条记录，2为每个epoch输出一行记录。\n",
    "\n",
    "# s = model.evaluate(X_test_s, y_test, verbose=0)\n",
    "fig, ax = plt.subplots(figsize=(8, 6), dpi=100)\n",
    "# 绘制训练集验证集损失变化\n",
    "\"\"\"\n",
    "训练过程中的损失函数变化情况\n",
    "模型在训练集上的损失远小于验证集的损失，说明模型过度拟合，但总体准确度已经较为准确。\n",
    "在训练的后期（大约150个epoch之后），验证集MSE下降速度很慢。这可能表明模型容量过大或正则化不足，可以适当增加正则化系数。\n",
    "\"\"\"\n",
    "ax.plot(hist.history['mse'], 'k', label='Train')\n",
    "ax.plot(hist.history['val_mse'], 'b', label='Validation')\n",
    "# plt.axvline(index,linestyle='--', color='k')\n",
    "ax.set_ylabel('MSE')\n",
    "ax.set_xlabel('Epoch')\n",
    "# ax.title('Mean Squared Error')\n",
    "# model.save(\"./assert/temp/bp_keras_model.keras\")\n",
    "# pd.DataFrame(hist.history).to_csv('./assert/bp_model_loss.csv')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "id": "f2ecf0de782ec114"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "params = {\n",
    "    \"objective\": 'mse',\n",
    "    'max_depth': 4,\n",
    "    \"n_estimators\": 100,\n",
    "    \"learning_rate\": 0.1,\n",
    "    'min_child_samples': 6,\n",
    "    'reg_alpha': 0,\n",
    "    'reg_lambda': 0,\n",
    "    \"force_col_wise\": True,\n",
    "    \"subsample\": 0.8,\n",
    "    'colsample_bytree': 0.8,\n",
    "    # \"num_leaves\": 7  # 一般设置为(0, 2^max_depth - 1]的一个数值。是一个需要重点调节的参数，对模型性能影响很大。\n",
    "}\n",
    "param_range = np.arange(2, 7, 1)\n",
    "scores = {}\n",
    "for i in param_range:\n",
    "    model = LGBMRegressor(n_jobs=-1, random_state=rs, verbosity=-1, num_leaves=i, **params)\n",
    "    model.fit(X_train_s, y_train)\n",
    "    scores[i] = model.score(X_test_s, y_test)\n",
    "\n",
    "temp_data = pd.Series(scores)\n",
    "# _ind = min(scores, key=scores.get)\n",
    "plt.figure(figsize=[20, 5])\n",
    "temp_data.plot()\n",
    "plt.show()"
   ],
   "id": "d206e2e2198ec58a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
