{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-02-11T17:59:02.081303Z",
     "start_time": "2025-02-11T17:58:59.687355Z"
    }
   },
   "source": [
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "rs = 132\n",
    "dataset = pd.read_csv('./data/dataset.csv')\n",
    "dataset.set_index('股票简称', inplace=True)\n",
    "# print(dataset.shape[0])\n",
    "features = [\n",
    "    '净资产收益率(%)', '资产报酬率(%)', 'EBITDA率(%)', '营业利润率(%)', '投入资本回报率(%)', \n",
    "    '资产负债率(%)', '权益乘数(%)', '速动比率(%)', '现金流动负债比率(%)', '长期资本负债率(%)',\n",
    "    '营业收入增长率(%)', '资本保值增值率(%)', '总资产增长率(%)', '资本积累率(%)', '营业利润增长率(%)',\n",
    "    '总资产周转率', '应收账款周转率', '流动资产周转率', '存货周转率', '现金资产比率(%)', \n",
    "    '数字技术应用', '商业模式变革', '智能制造', '现代信息系统',\n",
    "    '客户集中度(%)', '供应商集中度(%)', '成本费用利润率(%)',\n",
    "    '研发人员占比(%)', '研发营收比(%)', '发明专利申请数',\n",
    "    '两权分离率(%)', '独董比例(%)', '董事会规模','股权集中度(%)',\n",
    "    '员工人均营收比(%)', '提供岗位增长率(%)', '员工收入增长率(%)',\n",
    "]\n",
    "label_name = '因子得分'\n",
    "unit_map = dataset[['股票代码', '行业代码', '所属省份']].to_dict()\n",
    "# 获取数据集和标签值\n",
    "y : pd.Series = dataset[label_name]\n",
    "X : pd.DataFrame = dataset[features].copy(deep=True).astype(\"float\")\n",
    "# 数据预处理：1.极差标准化；2.数据集划分。\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=rs)\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train_s = scaler.transform(X_train)\n",
    "X_test_s = scaler.transform(X_test)"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-11T17:59:02.819559Z",
     "start_time": "2025-02-11T17:59:02.082303Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.model_selection import KFold, GridSearchCV, cross_val_score\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "# 一般机器学习模型的训练与优化\n",
    "\n",
    "# 1.最小二乘线性回归\n",
    "model = LinearRegression(n_jobs=-1)\n",
    "model.fit(X_train_s, y_train)\n",
    "y_pred = model.predict(X_test_s)\n",
    "print(f\"OLS Regression | r2:{r2_score(y_test, y_pred)} | mean_squared_error:{mean_squared_error(y_test, y_pred):.2} | mean_absolute_error:{mean_absolute_error(y_test, y_pred):.2}。\\n 因子分析的结果实际是对原结果进行线性转化的过程，因此最小二乘法能够较为精确的计算出实际权重。\")"
   ],
   "id": "131fc53b9ebe80e3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OLS Regression | r2:1.0 | mean_squared_error:4.5e-27 | mean_absolute_error:5.4e-14。\n",
      " 因子分析的结果实际是对原结果进行线性转化的过程，因此最小二乘法能够较为精确的计算出实际权重。\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# 基于树模型的参数优化基本流程为：首先计算单个参数的大致范围，随后进行网格搜索。\n",
    "# 决策树算法优化思路:\n",
    "\n",
    "# 1.优化ccp_alpha(网格搜索)；\n",
    "\n",
    "# model = DecisionTreeRegressor(random_state=rs)\n",
    "# path = model.cost_complexity_pruning_path(X_train_s, y_train)\n",
    "# param_grid = {'ccp_alpha': path.ccp_alphas}\n",
    "# kfold = KFold(n_splits=10, shuffle=True, random_state=1)\n",
    "# model = GridSearchCV(DecisionTreeRegressor(random_state=rs), param_grid, cv=kfold)\n",
    "# model.fit(X_train_s, y_train)\n",
    "# print(model.best_params_)\n",
    "\n",
    "# 2.单参数优化；\n",
    "model = DecisionTreeRegressor(max_features=\"sqrt\", random_state=1)\n",
    "path = model.cost_complexity_pruning_path(X_train_s, y_train)\n",
    "param_grid = {\n",
    "    'ccp_alpha': path.ccp_alphas,  # 剪枝参数\n",
    "    'max_depth': np.arange(5, 15, 1),  # 决策树最大深度，用来防止过拟合; \n",
    "    'min_samples_split': np.arange(1, 3, 1),  # 分裂节点所需的最小样本数，也就是如果样本数小于这个值就不划分了。\n",
    "    'min_samples_leaf': np.arange(1, 4, 1)  # 叶节点所需的最小样本数，如果样本数小于这个，就不划分了。用来防止过拟合\n",
    "}\n",
    "# 2.网格法参数微调\n",
    "kfold = KFold(n_splits=10, shuffle=True, random_state=rs)\n",
    "model = GridSearchCV(DecisionTreeRegressor(max_features=\"sqrt\", random_state=rs), param_grid, cv=kfold, n_jobs=-1)\n",
    "model.fit(X_train_s, y_train)\n",
    "\n",
    "# 决策树最优超参数：{'ccp_alpha': 0.7814179316082759, 'max_depth': 11, 'min_samples_leaf': 1, 'min_samples_split': 2} ；综合得分0.7849455038096266\n",
    "print(f\"决策树最优超参数：{model.best_params_}\\n 综合得分{model.best_estimator_.score(X_test_s, y_test)}\")"
   ],
   "id": "5ee823de33dbfc86",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "# 随机森林参数优化：https://www.jianshu.com/p/f5b45a60289f\n",
    "param_grid = {\n",
    "    'max_depth': np.arange(2, 30, 1),  # 树的最大深度\n",
    "    'n_estimators': np.arange(2, 30, 1),  # 森林中树的数量\n",
    "    'min_samples_split': [2, 3, 4, 5],  # 分裂节点所需的最小样本数\n",
    "    'min_samples_leaf': [1, 2, 3],  # 叶节点所需的最小样本数\n",
    "    'max_features': np.arange(2, 30, 1)  # 每次分裂时考虑的特征数量\n",
    "}\n",
    "\n",
    "model = RandomForestRegressor(verbose=0, random_state=rs, min_samples_split=2, min_samples_leaf=2)\n",
    "kfold = KFold(n_splits=10, shuffle=True, random_state=rs)\n",
    "model = GridSearchCV(model, param_grid, cv=kfold, scoring='r2', verbose=0, n_jobs=-1)\n",
    "model.fit(X_train_s, y_train)\n",
    "# RandomForest 最优超参数：{'max_depth': 13, 'max_features': 11, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 7}\n",
    " # 综合得分0.8483375813154402\n",
    "\n",
    "print(f\"RandomForest 最优超参数：{model.best_params_}\\n 综合得分{model.best_estimator_.score(X_test_s, y_test)}\")"
   ],
   "id": "d27429b14924eb44",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from xgboost import XGBRegressor\n",
    "\n",
    "# 3.xgboost参数优化：https://www.cnblogs.com/showmeai/p/16037327.html；\n",
    "params = {\n",
    "   \"objective\": 'reg:squarederror',\n",
    "   \"n_estimators\": 10,\n",
    "   \"max_depth\": 9,\n",
    "   \"learning_rate\": 0.24,\n",
    "   \"subsample\": 0.2,\n",
    "   \"min_child_weight\": 1,\n",
    "   \"gamma\": 0.1,\n",
    "   \"colsample_bytree\": 0.8,\n",
    "   \"reg_alpha\": 0,\n",
    "   \"reg_lambda\": 0,\n",
    "   # \"scale_pos_weight\": 1,\n",
    "}\n",
    "param_grid = {\n",
    "    'n_estimators': np.arange(18, 24, 1),\n",
    "    'max_depth': np.arange(8, 12, 1),\n",
    "    'learning_rate': np.arange(0.15, 0.25, 0.01), # [0.05, 0.1, 0.2]\n",
    "    \"min_child_weight\": [4, 5, 6, 7],\n",
    "    # \"gamma\": [0, 0.1],\n",
    "    'subsample': np.arange(0.4, 0.7, 0.1),\n",
    "    'colsample_bytree': np.arange(0.95, 1.2, 0.01),\n",
    "}\n",
    "\n",
    "model = XGBRegressor(random_state=rs)\n",
    "kfold = KFold(n_splits=10, shuffle=True, random_state=rs)\n",
    "model = GridSearchCV(model, param_grid, cv=kfold, scoring='r2', verbose=0, n_jobs=-1)\n",
    "model.fit(X_train_s, y_train)  \n",
    "print(f\"XGBRegressor 最优超参数：{model.best_params_}\\n 综合得分{model.best_estimator_.score(X_test_s, y_test)}\")\n",
    "\n",
    "# XGBRegressor 最优超参数：{'colsample_bytree': 0.9800000000000001, 'gamma': 0.1, 'learning_rate': 0.2, 'max_depth': 11, 'min_child_weight': 5, 'n_estimators': 23, 'subsample': 0.5}   综合得分0.8801265955806522"
   ],
   "id": "5f9d54a550d7bc21",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-11T17:56:39.117657Z",
     "start_time": "2025-02-11T16:27:26.270676Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# from lightgbm import LGBMRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "# 4.catboost参数优化\n",
    "param_grid = {\n",
    "    'iterations': np.arange(100, 401, 30),\n",
    "    'depth': [1, 2, 8, 12], \n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'l2_leaf_reg': [0, 1],\n",
    "    'bagging_temperature': [0.0, 0.1, 0.3],\n",
    "    'border_count': np.arange(32, 128, 10)\n",
    "}\n",
    "model = CatBoostRegressor(random_state=rs, verbose=0, train_dir=None, **params)\n",
    "kfold = KFold(n_splits=10, shuffle=True, random_state=rs)\n",
    "model = GridSearchCV(model, param_grid, cv=kfold, scoring='r2', verbose=0, n_jobs=-1)\n",
    "model.fit(X_train_s, y_train) \n",
    "print(f\"XGBRegressor 最优超参数：{model.best_params_}\\n 综合得分{model.best_estimator_.score(X_test_s, y_test)}\")"
   ],
   "id": "6cb6ff27c8f16f51",
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "File \u001B[1;32m~\\.conda\\envs\\digital\\lib\\site-packages\\joblib\\parallel.py:1650\u001B[0m, in \u001B[0;36mParallel._get_outputs\u001B[1;34m(self, iterator, pre_dispatch)\u001B[0m\n\u001B[0;32m   1649\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backend\u001B[38;5;241m.\u001B[39mretrieval_context():\n\u001B[1;32m-> 1650\u001B[0m         \u001B[38;5;28;01myield from\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_retrieve()\n\u001B[0;32m   1652\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mGeneratorExit\u001B[39;00m:\n\u001B[0;32m   1653\u001B[0m     \u001B[38;5;66;03m# The generator has been garbage collected before being fully\u001B[39;00m\n\u001B[0;32m   1654\u001B[0m     \u001B[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001B[39;00m\n\u001B[0;32m   1655\u001B[0m     \u001B[38;5;66;03m# the user if necessary.\u001B[39;00m\n",
      "File \u001B[1;32m~\\.conda\\envs\\digital\\lib\\site-packages\\joblib\\parallel.py:1762\u001B[0m, in \u001B[0;36mParallel._retrieve\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1759\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m ((\u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jobs) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m) \u001B[38;5;129;01mor\u001B[39;00m\n\u001B[0;32m   1760\u001B[0m     (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jobs[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39mget_status(\n\u001B[0;32m   1761\u001B[0m         timeout\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtimeout) \u001B[38;5;241m==\u001B[39m TASK_PENDING)):\n\u001B[1;32m-> 1762\u001B[0m     \u001B[43mtime\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msleep\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m0.01\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1763\u001B[0m     \u001B[38;5;28;01mcontinue\u001B[39;00m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[140], line 16\u001B[0m\n\u001B[0;32m     14\u001B[0m kfold \u001B[38;5;241m=\u001B[39m KFold(n_splits\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m10\u001B[39m, shuffle\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, random_state\u001B[38;5;241m=\u001B[39mrs)\n\u001B[0;32m     15\u001B[0m model \u001B[38;5;241m=\u001B[39m GridSearchCV(model, param_grid, cv\u001B[38;5;241m=\u001B[39mkfold, scoring\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mr2\u001B[39m\u001B[38;5;124m'\u001B[39m, verbose\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m, n_jobs\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m---> 16\u001B[0m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_train_s\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m)\u001B[49m \n\u001B[0;32m     17\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mXGBRegressor 最优超参数：\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mmodel\u001B[38;5;241m.\u001B[39mbest_params_\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m 综合得分\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mmodel\u001B[38;5;241m.\u001B[39mbest_estimator_\u001B[38;5;241m.\u001B[39mscore(X_test_s,\u001B[38;5;250m \u001B[39my_test)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32m~\\.conda\\envs\\digital\\lib\\site-packages\\sklearn\\base.py:1389\u001B[0m, in \u001B[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001B[1;34m(estimator, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1382\u001B[0m     estimator\u001B[38;5;241m.\u001B[39m_validate_params()\n\u001B[0;32m   1384\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[0;32m   1385\u001B[0m     skip_parameter_validation\u001B[38;5;241m=\u001B[39m(\n\u001B[0;32m   1386\u001B[0m         prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[0;32m   1387\u001B[0m     )\n\u001B[0;32m   1388\u001B[0m ):\n\u001B[1;32m-> 1389\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m fit_method(estimator, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\.conda\\envs\\digital\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1024\u001B[0m, in \u001B[0;36mBaseSearchCV.fit\u001B[1;34m(self, X, y, **params)\u001B[0m\n\u001B[0;32m   1018\u001B[0m     results \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_format_results(\n\u001B[0;32m   1019\u001B[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001B[0;32m   1020\u001B[0m     )\n\u001B[0;32m   1022\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m results\n\u001B[1;32m-> 1024\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_run_search\u001B[49m\u001B[43m(\u001B[49m\u001B[43mevaluate_candidates\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1026\u001B[0m \u001B[38;5;66;03m# multimetric is determined here because in the case of a callable\u001B[39;00m\n\u001B[0;32m   1027\u001B[0m \u001B[38;5;66;03m# self.scoring the return type is only known after calling\u001B[39;00m\n\u001B[0;32m   1028\u001B[0m first_test_score \u001B[38;5;241m=\u001B[39m all_out[\u001B[38;5;241m0\u001B[39m][\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtest_scores\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n",
      "File \u001B[1;32m~\\.conda\\envs\\digital\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1571\u001B[0m, in \u001B[0;36mGridSearchCV._run_search\u001B[1;34m(self, evaluate_candidates)\u001B[0m\n\u001B[0;32m   1569\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21m_run_search\u001B[39m(\u001B[38;5;28mself\u001B[39m, evaluate_candidates):\n\u001B[0;32m   1570\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001B[39;00m\n\u001B[1;32m-> 1571\u001B[0m     \u001B[43mevaluate_candidates\u001B[49m\u001B[43m(\u001B[49m\u001B[43mParameterGrid\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mparam_grid\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\.conda\\envs\\digital\\lib\\site-packages\\sklearn\\model_selection\\_search.py:970\u001B[0m, in \u001B[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001B[1;34m(candidate_params, cv, more_results)\u001B[0m\n\u001B[0;32m    962\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mverbose \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m    963\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\n\u001B[0;32m    964\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFitting \u001B[39m\u001B[38;5;132;01m{0}\u001B[39;00m\u001B[38;5;124m folds for each of \u001B[39m\u001B[38;5;132;01m{1}\u001B[39;00m\u001B[38;5;124m candidates,\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    965\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m totalling \u001B[39m\u001B[38;5;132;01m{2}\u001B[39;00m\u001B[38;5;124m fits\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(\n\u001B[0;32m    966\u001B[0m             n_splits, n_candidates, n_candidates \u001B[38;5;241m*\u001B[39m n_splits\n\u001B[0;32m    967\u001B[0m         )\n\u001B[0;32m    968\u001B[0m     )\n\u001B[1;32m--> 970\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[43mparallel\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    971\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdelayed\u001B[49m\u001B[43m(\u001B[49m\u001B[43m_fit_and_score\u001B[49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    972\u001B[0m \u001B[43m        \u001B[49m\u001B[43mclone\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbase_estimator\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    973\u001B[0m \u001B[43m        \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    974\u001B[0m \u001B[43m        \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    975\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtrain\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    976\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtest\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtest\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    977\u001B[0m \u001B[43m        \u001B[49m\u001B[43mparameters\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mparameters\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    978\u001B[0m \u001B[43m        \u001B[49m\u001B[43msplit_progress\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43msplit_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_splits\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    979\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcandidate_progress\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcand_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_candidates\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    980\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mfit_and_score_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    981\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    982\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43mcand_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mparameters\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43msplit_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtest\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mproduct\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    983\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43menumerate\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcandidate_params\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    984\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43menumerate\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcv\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msplit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mrouted_params\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msplitter\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msplit\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    985\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    986\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    988\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(out) \u001B[38;5;241m<\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[0;32m    989\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    990\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNo fits were performed. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    991\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mWas the CV iterator empty? \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    992\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mWere there no candidates?\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    993\u001B[0m     )\n",
      "File \u001B[1;32m~\\.conda\\envs\\digital\\lib\\site-packages\\sklearn\\utils\\parallel.py:77\u001B[0m, in \u001B[0;36mParallel.__call__\u001B[1;34m(self, iterable)\u001B[0m\n\u001B[0;32m     72\u001B[0m config \u001B[38;5;241m=\u001B[39m get_config()\n\u001B[0;32m     73\u001B[0m iterable_with_config \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m     74\u001B[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001B[0;32m     75\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m delayed_func, args, kwargs \u001B[38;5;129;01min\u001B[39;00m iterable\n\u001B[0;32m     76\u001B[0m )\n\u001B[1;32m---> 77\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__call__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43miterable_with_config\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\.conda\\envs\\digital\\lib\\site-packages\\joblib\\parallel.py:2007\u001B[0m, in \u001B[0;36mParallel.__call__\u001B[1;34m(self, iterable)\u001B[0m\n\u001B[0;32m   2001\u001B[0m \u001B[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001B[39;00m\n\u001B[0;32m   2002\u001B[0m \u001B[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001B[39;00m\n\u001B[0;32m   2003\u001B[0m \u001B[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001B[39;00m\n\u001B[0;32m   2004\u001B[0m \u001B[38;5;66;03m# dispatch of the tasks to the workers.\u001B[39;00m\n\u001B[0;32m   2005\u001B[0m \u001B[38;5;28mnext\u001B[39m(output)\n\u001B[1;32m-> 2007\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m output \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mreturn_generator \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;43mlist\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43moutput\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\.conda\\envs\\digital\\lib\\site-packages\\joblib\\parallel.py:1703\u001B[0m, in \u001B[0;36mParallel._get_outputs\u001B[1;34m(self, iterator, pre_dispatch)\u001B[0m\n\u001B[0;32m   1701\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mBaseException\u001B[39;00m:\n\u001B[0;32m   1702\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_exception \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m-> 1703\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_abort\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1704\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m\n\u001B[0;32m   1705\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m   1706\u001B[0m     \u001B[38;5;66;03m# Store the unconsumed tasks and terminate the workers if necessary\u001B[39;00m\n",
      "File \u001B[1;32m~\\.conda\\envs\\digital\\lib\\site-packages\\joblib\\parallel.py:1614\u001B[0m, in \u001B[0;36mParallel._abort\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1609\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_aborted \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(backend, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mabort_everything\u001B[39m\u001B[38;5;124m'\u001B[39m)):\n\u001B[0;32m   1610\u001B[0m     \u001B[38;5;66;03m# If the backend is managed externally we need to make sure\u001B[39;00m\n\u001B[0;32m   1611\u001B[0m     \u001B[38;5;66;03m# to leave it in a working state to allow for future jobs\u001B[39;00m\n\u001B[0;32m   1612\u001B[0m     \u001B[38;5;66;03m# scheduling.\u001B[39;00m\n\u001B[0;32m   1613\u001B[0m     ensure_ready \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_managed_backend\n\u001B[1;32m-> 1614\u001B[0m     \u001B[43mbackend\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mabort_everything\u001B[49m\u001B[43m(\u001B[49m\u001B[43mensure_ready\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mensure_ready\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1615\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_aborted \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "File \u001B[1;32m~\\.conda\\envs\\digital\\lib\\site-packages\\joblib\\_parallel_backends.py:620\u001B[0m, in \u001B[0;36mLokyBackend.abort_everything\u001B[1;34m(self, ensure_ready)\u001B[0m\n\u001B[0;32m    617\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mabort_everything\u001B[39m(\u001B[38;5;28mself\u001B[39m, ensure_ready\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m):\n\u001B[0;32m    618\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Shutdown the workers and restart a new one with the same parameters\u001B[39;00m\n\u001B[0;32m    619\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 620\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_workers\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mterminate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkill_workers\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[0;32m    621\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_workers \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    623\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m ensure_ready:\n",
      "File \u001B[1;32m~\\.conda\\envs\\digital\\lib\\site-packages\\joblib\\executor.py:75\u001B[0m, in \u001B[0;36mMemmappingExecutor.terminate\u001B[1;34m(self, kill_workers)\u001B[0m\n\u001B[0;32m     73\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mterminate\u001B[39m(\u001B[38;5;28mself\u001B[39m, kill_workers\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m):\n\u001B[1;32m---> 75\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mshutdown\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkill_workers\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mkill_workers\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     77\u001B[0m     \u001B[38;5;66;03m# When workers are killed in a brutal manner, they cannot execute the\u001B[39;00m\n\u001B[0;32m     78\u001B[0m     \u001B[38;5;66;03m# finalizer of their shared memmaps. The refcount of those memmaps may\u001B[39;00m\n\u001B[0;32m     79\u001B[0m     \u001B[38;5;66;03m# be off by an unknown number, so instead of decref'ing them, we force\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     84\u001B[0m     \u001B[38;5;66;03m# with allow_non_empty=True but if we can't, it will be clean up later\u001B[39;00m\n\u001B[0;32m     85\u001B[0m     \u001B[38;5;66;03m# on by the resource_tracker.\u001B[39;00m\n\u001B[0;32m     86\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_submit_resize_lock:\n",
      "File \u001B[1;32m~\\.conda\\envs\\digital\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py:1303\u001B[0m, in \u001B[0;36mProcessPoolExecutor.shutdown\u001B[1;34m(self, wait, kill_workers)\u001B[0m\n\u001B[0;32m   1299\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m executor_manager_thread \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m wait:\n\u001B[0;32m   1300\u001B[0m     \u001B[38;5;66;03m# This locks avoids concurrent join if the interpreter\u001B[39;00m\n\u001B[0;32m   1301\u001B[0m     \u001B[38;5;66;03m# is shutting down.\u001B[39;00m\n\u001B[0;32m   1302\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m _global_shutdown_lock:\n\u001B[1;32m-> 1303\u001B[0m         \u001B[43mexecutor_manager_thread\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mjoin\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1304\u001B[0m         _threads_wakeups\u001B[38;5;241m.\u001B[39mpop(executor_manager_thread, \u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[0;32m   1306\u001B[0m \u001B[38;5;66;03m# To reduce the risk of opening too many files, remove references to\u001B[39;00m\n\u001B[0;32m   1307\u001B[0m \u001B[38;5;66;03m# objects that use file descriptors.\u001B[39;00m\n",
      "File \u001B[1;32m~\\.conda\\envs\\digital\\lib\\threading.py:1060\u001B[0m, in \u001B[0;36mThread.join\u001B[1;34m(self, timeout)\u001B[0m\n\u001B[0;32m   1057\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcannot join current thread\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m   1059\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m timeout \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m-> 1060\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_wait_for_tstate_lock\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1061\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   1062\u001B[0m     \u001B[38;5;66;03m# the behavior of a negative timeout isn't documented, but\u001B[39;00m\n\u001B[0;32m   1063\u001B[0m     \u001B[38;5;66;03m# historically .join(timeout=x) for x<0 has acted as if timeout=0\u001B[39;00m\n\u001B[0;32m   1064\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_wait_for_tstate_lock(timeout\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mmax\u001B[39m(timeout, \u001B[38;5;241m0\u001B[39m))\n",
      "File \u001B[1;32m~\\.conda\\envs\\digital\\lib\\threading.py:1080\u001B[0m, in \u001B[0;36mThread._wait_for_tstate_lock\u001B[1;34m(self, block, timeout)\u001B[0m\n\u001B[0;32m   1077\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m\n\u001B[0;32m   1079\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m-> 1080\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[43mlock\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43macquire\u001B[49m\u001B[43m(\u001B[49m\u001B[43mblock\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m:\n\u001B[0;32m   1081\u001B[0m         lock\u001B[38;5;241m.\u001B[39mrelease()\n\u001B[0;32m   1082\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_stop()\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 140
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "params = {\n",
    "    \"iterations\": 100,  # 越大越好300\n",
    "    \"learning_rate\": 0.2,  # 可能处于 0.01~0.5或0.6~0.9之间，前者可能性更大\n",
    "    \"depth\": 5,\n",
    "    \"l2_leaf_reg\": 1,\n",
    "    'bagging_temperature': 0,\n",
    "    # \"border_count\": 64  # 越大越好，\n",
    "}\n",
    "param_range = np.arange(1, 200, 10)\n",
    "scores = {}\n",
    "for i in param_range:\n",
    "    model = CatBoostRegressor(random_state=rs, verbose=0, train_dir=None, border_count=i, **params)\n",
    "    model.fit(X_train_s, y_train)\n",
    "    scores[i] = model.score(X_test_s, y_test)\n",
    "\n",
    "temp_data = pd.Series(scores)\n",
    "# _ind = min(scores, key=scores.get)\n",
    "plt.figure(figsize=[20, 5])\n",
    "temp_data.plot()\n",
    "plt.show()"
   ],
   "id": "1de8383c1caec18c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from utils.mlkits import r2_score\n",
    "from tensorflow import keras\n",
    "\n",
    "# 神经网络模型训练与优化\n",
    "\n",
    "# Sequential 模型适用于普通层堆栈 其中，每层只有一个 input Tensor 和一个 Output Tensor。\n",
    "model = keras.models.Sequential()\n",
    "# model.add(keras.Input(shape=(X_train_s.shape[1], )))\n",
    "model.add(keras.layers.Dense(units=15, activation='relu', name=\"layer1\", input_shape=(X_train_s.shape[1], ),\n",
    "                               kernel_regularizer=keras.regularizers.l2(0.02)))\n",
    "model.add(keras.layers.Dropout(0.08))\n",
    "\n",
    "# 增加输出层\n",
    "model.add(keras.layers.Dense(units=1, name=\"output\"))\n",
    "optimizer = keras.optimizers.Adam(learning_rate=9e-3)\n",
    "model.compile(optimizer=optimizer, loss='mse', metrics=['mse', r2_score, 'mae'])\n",
    "# 查看模型结构\n",
    "# utils.plot_model(model, \"./assert/feature_importance/bp_model_structure.png\", show_shapes=True)\n",
    "# model.summary()\n",
    "early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)\n",
    "hist = model.fit(X_train_s, y_train, validation_split=0.3, epochs=300, batch_size=30, shuffle=False, verbose=0,\n",
    "                         callbacks=[early_stopping])\n",
    "# validation_split是训练集验证集拆分，epochs代表训练300轮，batch_size代表在批量梯度下降时每次选择16个样本，shuffle代表在训练过程中不会将数据反复打乱\n",
    "# verbose：日志显示，0为不在标准输出流输出日志信息，1为输出进度条记录，2为每个epoch输出一行记录。\n",
    "s = model.evaluate(X_test_s, y_test, verbose=0)\n",
    "print(f'测试集mse得分:{s[1]:.3%}，R^2得分{s[2]:.3%}')\n",
    "\n",
    "\n",
    "model.save(\"./assert/temp/bp_keras_model.keras\")\n",
    "pd.DataFrame(hist.history).to_csv('./assert/bp_model_loss.csv')"
   ],
   "id": "7ded976479f61052",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
