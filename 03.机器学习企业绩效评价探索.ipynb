{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-02-11T22:03:40.848039Z",
     "start_time": "2025-02-11T22:03:40.539435Z"
    }
   },
   "source": [
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "rs = 132\n",
    "dataset = pd.read_csv('./data/dataset.csv')\n",
    "dataset.set_index('股票简称', inplace=True)\n",
    "# print(dataset.shape[0])\n",
    "features = [\n",
    "    '净资产收益率(%)', '资产报酬率(%)', 'EBITDA率(%)', '营业利润率(%)', '投入资本回报率(%)', \n",
    "    '资产负债率(%)', '权益乘数(%)', '速动比率(%)', '现金流动负债比率(%)', '长期资本负债率(%)',\n",
    "    '营业收入增长率(%)', '资本保值增值率(%)', '总资产增长率(%)', '资本积累率(%)', '营业利润增长率(%)',\n",
    "    '总资产周转率', '应收账款周转率', '流动资产周转率', '存货周转率', '现金资产比率(%)', \n",
    "    '数字技术应用', '商业模式变革', '智能制造', '现代信息系统',\n",
    "    '客户集中度(%)', '供应商集中度(%)', '成本费用利润率(%)',\n",
    "    '研发人员占比(%)', '研发营收比(%)', '发明专利申请数',\n",
    "    '两权分离率(%)', '独董比例(%)', '董事会规模','股权集中度(%)',\n",
    "    '员工人均营收比(%)', '提供岗位增长率(%)', '员工收入增长率(%)',\n",
    "]\n",
    "label_name = '因子得分'\n",
    "unit_map = dataset[['股票代码', '行业代码', '所属省份']].to_dict()\n",
    "# 获取数据集和标签值\n",
    "y : pd.Series = dataset[label_name]\n",
    "X : pd.DataFrame = dataset[features].copy(deep=True).astype(\"float\")\n",
    "# 数据预处理：1.极差标准化；2.数据集划分。\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=rs)\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train_s = scaler.transform(X_train)\n",
    "X_test_s = scaler.transform(X_test)"
   ],
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[1], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mwarnings\u001B[39;00m\n\u001B[1;32m----> 2\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mpandas\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mas\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mpd\u001B[39;00m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mnumpy\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mas\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mnp\u001B[39;00m\n\u001B[0;32m      4\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01msklearn\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpreprocessing\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m MinMaxScaler\n",
      "File \u001B[1;32m~\\.conda\\envs\\digital\\lib\\site-packages\\pandas\\__init__.py:29\u001B[0m\n\u001B[0;32m     22\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mpandas\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcompat\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mnumpy\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[0;32m     23\u001B[0m     np_version_under1p17 \u001B[38;5;28;01mas\u001B[39;00m _np_version_under1p17,\n\u001B[0;32m     24\u001B[0m     np_version_under1p18 \u001B[38;5;28;01mas\u001B[39;00m _np_version_under1p18,\n\u001B[0;32m     25\u001B[0m     is_numpy_dev \u001B[38;5;28;01mas\u001B[39;00m _is_numpy_dev,\n\u001B[0;32m     26\u001B[0m )\n\u001B[0;32m     28\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m---> 29\u001B[0m     \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mpandas\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_libs\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m hashtable \u001B[38;5;28;01mas\u001B[39;00m _hashtable, lib \u001B[38;5;28;01mas\u001B[39;00m _lib, tslib \u001B[38;5;28;01mas\u001B[39;00m _tslib\n\u001B[0;32m     30\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mImportError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:  \u001B[38;5;66;03m# pragma: no cover\u001B[39;00m\n\u001B[0;32m     31\u001B[0m     \u001B[38;5;66;03m# hack but overkill to use re\u001B[39;00m\n\u001B[0;32m     32\u001B[0m     module \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mstr\u001B[39m(e)\u001B[38;5;241m.\u001B[39mreplace(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcannot import name \u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32m~\\.conda\\envs\\digital\\lib\\site-packages\\pandas\\_libs\\__init__.py:13\u001B[0m\n\u001B[0;32m      1\u001B[0m __all__ \u001B[38;5;241m=\u001B[39m [\n\u001B[0;32m      2\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNaT\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m      3\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNaTType\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m      9\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mInterval\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m     10\u001B[0m ]\n\u001B[1;32m---> 13\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mpandas\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_libs\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01minterval\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m Interval\n\u001B[0;32m     14\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mpandas\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_libs\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtslibs\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[0;32m     15\u001B[0m     NaT,\n\u001B[0;32m     16\u001B[0m     NaTType,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     21\u001B[0m     iNaT,\n\u001B[0;32m     22\u001B[0m )\n",
      "File \u001B[1;32mpandas\\_libs\\interval.pyx:1\u001B[0m, in \u001B[0;36minit pandas._libs.interval\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;31mValueError\u001B[0m: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.model_selection import KFold, GridSearchCV, cross_val_score\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "# 一般机器学习模型的训练与优化\n",
    "\n",
    "# 1.最小二乘线性回归\n",
    "model = LinearRegression(n_jobs=-1)\n",
    "model.fit(X_train_s, y_train)\n",
    "y_pred = model.predict(X_test_s)\n",
    "print(f\"OLS Regression | r2:{r2_score(y_test, y_pred)} | mean_squared_error:{mean_squared_error(y_test, y_pred):.2} | mean_absolute_error:{mean_absolute_error(y_test, y_pred):.2}。\\n 因子分析的结果实际是对原结果进行线性转化的过程，因此最小二乘法能够较为精确的计算出实际权重。\")"
   ],
   "id": "131fc53b9ebe80e3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# 基于树模型的参数优化基本流程为：首先计算单个参数的大致范围，随后进行网格搜索。\n",
    "# 决策树算法优化思路:\n",
    "\n",
    "# 1.优化ccp_alpha(网格搜索)；\n",
    "\n",
    "# model = DecisionTreeRegressor(random_state=rs)\n",
    "# path = model.cost_complexity_pruning_path(X_train_s, y_train)\n",
    "# param_grid = {'ccp_alpha': path.ccp_alphas}\n",
    "# kfold = KFold(n_splits=10, shuffle=True, random_state=1)\n",
    "# model = GridSearchCV(DecisionTreeRegressor(random_state=rs), param_grid, cv=kfold)\n",
    "# model.fit(X_train_s, y_train)\n",
    "# print(model.best_params_)\n",
    "\n",
    "# 2.单参数优化；\n",
    "model = DecisionTreeRegressor(max_features=\"sqrt\", random_state=1)\n",
    "path = model.cost_complexity_pruning_path(X_train_s, y_train)\n",
    "param_grid = {\n",
    "    'ccp_alpha': path.ccp_alphas,  # 剪枝参数\n",
    "    'max_depth': np.arange(5, 15, 1),  # 决策树最大深度，用来防止过拟合; \n",
    "    'min_samples_split': np.arange(1, 3, 1),  # 分裂节点所需的最小样本数，也就是如果样本数小于这个值就不划分了。\n",
    "    'min_samples_leaf': np.arange(1, 4, 1)  # 叶节点所需的最小样本数，如果样本数小于这个，就不划分了。用来防止过拟合\n",
    "}\n",
    "# 2.网格法参数微调\n",
    "kfold = KFold(n_splits=10, shuffle=True, random_state=rs)\n",
    "model = GridSearchCV(DecisionTreeRegressor(max_features=\"sqrt\", random_state=rs), param_grid, cv=kfold, n_jobs=-1)\n",
    "model.fit(X_train_s, y_train)\n",
    "\n",
    "# 决策树最优超参数：{'ccp_alpha': 0.7814179316082759, 'max_depth': 11, 'min_samples_leaf': 1, 'min_samples_split': 2} ；综合得分0.7849455038096266\n",
    "print(f\"决策树最优超参数：{model.best_params_}\\n 综合得分{model.best_estimator_.score(X_test_s, y_test)}\")"
   ],
   "id": "5ee823de33dbfc86",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "# 随机森林参数优化：https://www.jianshu.com/p/f5b45a60289f\n",
    "param_grid = {\n",
    "    'max_depth': np.arange(2, 30, 1),  # 树的最大深度\n",
    "    'n_estimators': np.arange(2, 30, 1),  # 森林中树的数量\n",
    "    'min_samples_split': [2, 3, 4, 5],  # 分裂节点所需的最小样本数\n",
    "    'min_samples_leaf': [1, 2, 3],  # 叶节点所需的最小样本数\n",
    "    'max_features': np.arange(2, 30, 1)  # 每次分裂时考虑的特征数量\n",
    "}\n",
    "\n",
    "model = RandomForestRegressor(verbose=0, random_state=rs, min_samples_split=2, min_samples_leaf=2)\n",
    "kfold = KFold(n_splits=10, shuffle=True, random_state=rs)\n",
    "model = GridSearchCV(model, param_grid, cv=kfold, scoring='r2', verbose=0, n_jobs=-1)\n",
    "model.fit(X_train_s, y_train)\n",
    "# RandomForest 最优超参数：{'max_depth': 13, 'max_features': 11, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 7}\n",
    " # 综合得分0.8483375813154402\n",
    "\n",
    "print(f\"RandomForest 最优超参数：{model.best_params_}\\n 综合得分{model.best_estimator_.score(X_test_s, y_test)}\")"
   ],
   "id": "d27429b14924eb44",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from xgboost import XGBRegressor\n",
    "\n",
    "# 3.xgboost参数优化：https://www.cnblogs.com/showmeai/p/16037327.html；\n",
    "params = {\n",
    "   \"objective\": 'reg:squarederror',\n",
    "   \"n_estimators\": 10,\n",
    "   \"max_depth\": 9,\n",
    "   \"learning_rate\": 0.24,\n",
    "   \"subsample\": 0.2,\n",
    "   \"min_child_weight\": 1,\n",
    "   \"gamma\": 0.1,\n",
    "   \"colsample_bytree\": 0.8,\n",
    "   \"reg_alpha\": 0,\n",
    "   \"reg_lambda\": 0,\n",
    "   # \"scale_pos_weight\": 1,\n",
    "}\n",
    "param_grid = {\n",
    "    'n_estimators': np.arange(18, 24, 1),\n",
    "    'max_depth': np.arange(8, 12, 1),\n",
    "    'learning_rate': np.arange(0.15, 0.25, 0.01), # [0.05, 0.1, 0.2]\n",
    "    \"min_child_weight\": [4, 5, 6, 7],\n",
    "    # \"gamma\": [0, 0.1],\n",
    "    'subsample': np.arange(0.4, 0.7, 0.1),\n",
    "    'colsample_bytree': np.arange(0.95, 1.2, 0.01),\n",
    "}\n",
    "\n",
    "model = XGBRegressor(random_state=rs)\n",
    "kfold = KFold(n_splits=10, shuffle=True, random_state=rs)\n",
    "model = GridSearchCV(model, param_grid, cv=kfold, scoring='r2', verbose=0, n_jobs=-1)\n",
    "model.fit(X_train_s, y_train)  \n",
    "print(f\"XGBRegressor 最优超参数：{model.best_params_}\\n 综合得分{model.best_estimator_.score(X_test_s, y_test)}\")\n",
    "\n",
    "# XGBRegressor 最优超参数：{'colsample_bytree': 0.9800000000000001, 'gamma': 0.1, 'learning_rate': 0.2, 'max_depth': 11, 'min_child_weight': 5, 'n_estimators': 23, 'subsample': 0.5}   综合得分0.8801265955806522"
   ],
   "id": "5f9d54a550d7bc21",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from catboost import CatBoostRegressor\n",
    "\n",
    "# 4.catboost参数优化\n",
    "param_grid = {\n",
    "    # 'iterations': np.arange(100, 401, 50),\n",
    "    'depth': [2, 3, 4, 5], \n",
    "    'learning_rate': np.arange(0.14, 0.38, 0.01),\n",
    "    'l2_leaf_reg': np.arange(0.2, 1.6, 0.1),\n",
    "    # 'bagging_temperature': [0.1, 0.3],\n",
    "    # 'border_count': np.arange(35, 190, 1)\n",
    "}\n",
    "# 分布计算\n",
    "model = CatBoostRegressor(random_state=rs, verbose=0, train_dir=None, allow_writing_files=False, iterations=400, bagging_temperature=0.1, border_count=182)\n",
    "kfold = KFold(n_splits=10, shuffle=True, random_state=rs)\n",
    "model = GridSearchCV(model, param_grid, cv=kfold, scoring='r2', verbose=0, n_jobs=-1)\n",
    "model.fit(X_train_s, y_train) \n",
    "print(f\"CatBoost 最优超参数：{model.best_params_}\\n 综合得分{model.best_estimator_.score(X_test_s, y_test)}\")\n",
    "\n",
    "# CatBoost 最优超参数：{'depth': 2, 'l2_leaf_reg': 0.6000000000000001, 'learning_rate': 0.15000000000000002} 综合得分0.9445921278676876"
   ],
   "id": "6cb6ff27c8f16f51",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "params = {\n",
    "    \"objective\": 'mse',\n",
    "    'max_depth': 3,\n",
    "    \"n_estimators\": 200,\n",
    "    \"learning_rate\": 0.1,\n",
    "    'min_child_samples': 7,\n",
    "    'reg_alpha': 0,\n",
    "    'reg_lambda': 0,\n",
    "    \"force_col_wise\": True,\n",
    "    \"subsample\": 0.8,\n",
    "    'colsample_bytree': 0.26,\n",
    "    \"num_leaves\": 7  # 一般设置为(0, 2^max_depth - 1]的一个数值。是一个需要重点调节的参数，对模型性能影响很大。\n",
    "}\n",
    "param_grid = {\n",
    "    'max_depth': [2, 3, 4, 5],\n",
    "    'learning_rate': [0.06, 0.1, 0.12, 0.17, 0.23, 0.24, 0.25, 0.27],\n",
    "    # \"n_estimators\": 100,\n",
    "    'min_child_samples': [5, 6, 7, 8], # 6附近\n",
    "    'colsample_bytree': np.arange(0.25, 0.45, 0.01),  # 0.25和0.45附近\n",
    "    \"num_leaves\": np.arange(3, 8, 1)\n",
    "}\n",
    "model = LGBMRegressor(n_jobs=-1, random_state=rs, verbosity=-1, **params)\n",
    "kfold = KFold(n_splits=10, shuffle=True, random_state=rs)\n",
    "model = GridSearchCV(model, param_grid, cv=kfold, scoring='r2', verbose=0, n_jobs=-1)\n",
    "model.fit(X_train_s, y_train) \n",
    "print(f\"LGBMBoost 最优超参数：{model.best_params_}\\n 综合得分{model.best_estimator_.score(X_test_s, y_test)}\")"
   ],
   "id": "7fb2d0875d95af1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from lightgbm import LGBMRegressor\n",
    "params = {\n",
    "    \"objective\": 'mse',\n",
    "    'max_depth': 3,\n",
    "    \"n_estimators\": 200,\n",
    "    'learning_rate': 0.15,\n",
    "    'min_child_samples': 7, \n",
    "    'reg_alpha': 0,\n",
    "    'reg_lambda': 0,\n",
    "    \"force_col_wise\": True,\n",
    "    \"subsample\": 0.8,\n",
    "    'colsample_bytree': 0.32,\n",
    "    \"num_leaves\": 6\n",
    "}\n",
    "model = LGBMRegressor(n_jobs=-1, random_state=rs, verbosity=-1, **params)\n",
    "model.fit(X_train_s, y_train)\n",
    "print(model.score(X_test_s, y_test))"
   ],
   "id": "671edd0789e1e7d1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from tensorflow import keras\n",
    "from utils.mlkits import r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['font.family'] = 'serif'\n",
    "plt.rcParams['font.serif'] = 'Times New Roman'\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "# font = {\"fontfamily\": \"Songti SC\", \"fontsize\":10}\n",
    "\n",
    "\n",
    "# 神经网络模型训练与优化\n",
    "\n",
    "# Sequential 模型适用于普通层堆栈 其中，每层只有一个 input Tensor 和一个 Output Tensor。\n",
    "model = keras.models.Sequential()\n",
    "# model.add(keras.Input(shape=(X_train_s.shape[1], )))\n",
    "model.add(keras.layers.Dense(units=15, activation='relu', name=\"layer1\", input_shape=(X_train_s.shape[1], ),\n",
    "                               kernel_regularizer=keras.regularizers.l2(0.02)))\n",
    "model.add(keras.layers.Dropout(0.08))\n",
    "\n",
    "# 增加输出层\n",
    "model.add(keras.layers.Dense(units=1, name=\"output\"))\n",
    "optimizer = keras.optimizers.Adam(learning_rate=9e-3)\n",
    "model.compile(optimizer=optimizer, loss='mse', metrics=['mse', r2_score, 'mae'])\n",
    "# 查看模型结构\n",
    "# utils.plot_model(model, \"./assert/feature_importance/bp_model_structure.png\", show_shapes=True)\n",
    "# model.summary()\n",
    "early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)\n",
    "hist = model.fit(X_train_s, y_train, validation_split=0.3, epochs=300, batch_size=30, shuffle=False, verbose=0,\n",
    "                         callbacks=[early_stopping])\n",
    "# validation_split是训练集验证集拆分，epochs代表训练300轮，batch_size代表在批量梯度下降时每次选择16个样本，shuffle代表在训练过程中不会将数据反复打乱\n",
    "# verbose：日志显示，0为不在标准输出流输出日志信息，1为输出进度条记录，2为每个epoch输出一行记录。\n",
    "s = model.evaluate(X_test_s, y_test, verbose=0)\n",
    "print(f'测试集mse得分:{s[1]:.3%}，R^2得分{s[2]:.3%}')\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 6), dpi=100)\n",
    "# 绘制训练集验证集损失变化\n",
    "\"\"\"\n",
    "训练过程中的损失函数变化情况\n",
    "模型在训练集上的损失远小于验证集的损失，说明模型过度拟合，但总体准确度已经较为准确。\n",
    "在训练的后期（大约150个epoch之后），验证集MSE下降速度很慢。这可能表明模型容量过大或正则化不足，可以适当增加正则化系数。\n",
    "\"\"\"\n",
    "ax.plot(hist.history['mse'], 'k', label='Train')\n",
    "ax.plot(hist.history['val_mse'], 'b', label='Validation')\n",
    "# plt.axvline(index,linestyle='--', color='k')\n",
    "ax.set_ylabel('MSE')\n",
    "ax.set_xlabel('Epoch')\n",
    "# ax.title('Mean Squared Error')\n",
    "# model.save(\"./assert/temp/bp_keras_model.keras\")\n",
    "# pd.DataFrame(hist.history).to_csv('./assert/bp_model_loss.csv')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "id": "32459f629761bce3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "params = {\n",
    "    \"objective\": 'mse',\n",
    "    'max_depth': 4,\n",
    "    \"n_estimators\": 100,\n",
    "    \"learning_rate\": 0.1,\n",
    "    'min_child_samples': 6,\n",
    "    'reg_alpha': 0,\n",
    "    'reg_lambda': 0,\n",
    "    \"force_col_wise\": True,\n",
    "    \"subsample\": 0.8,\n",
    "    'colsample_bytree': 0.8,\n",
    "    # \"num_leaves\": 7  # 一般设置为(0, 2^max_depth - 1]的一个数值。是一个需要重点调节的参数，对模型性能影响很大。\n",
    "}\n",
    "param_range = np.arange(2, 7, 1)\n",
    "scores = {}\n",
    "for i in param_range:\n",
    "    model = LGBMRegressor(n_jobs=-1, random_state=rs, verbosity=-1, num_leaves=i, **params)\n",
    "    model.fit(X_train_s, y_train)\n",
    "    scores[i] = model.score(X_test_s, y_test)\n",
    "\n",
    "temp_data = pd.Series(scores)\n",
    "# _ind = min(scores, key=scores.get)\n",
    "plt.figure(figsize=[20, 5])\n",
    "temp_data.plot()\n",
    "plt.show()"
   ],
   "id": "b1a87bc3e4a67983",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
